{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099b498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lonewolf/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lonewolf/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f026b03-baf3-4e43-85c0-b767143ce134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "host = \"https://munichre-gsi.aihub.instabase.com\"\n",
    "token = \"4S6sYTbnpx5WwM6RNQBM5rSWI8JTZR\"\n",
    "workspace = \"GSI-ModelLab\"\n",
    "org = \"munichre\"\n",
    "job_ids = []\n",
    "case_names = {}  \n",
    "\n",
    "def create_batch():\n",
    "    print(org, workspace,token, host)\n",
    "    response = requests.post(\n",
    "        f\"{host}/api/v2/batches\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Ib-Context\": org\n",
    "        },\n",
    "        json={\n",
    "            \"name\": \"batch_1\",\n",
    "            \"workspace\": workspace\n",
    "        },\n",
    "       verify = False\n",
    "    )\n",
    "    print(response.text)\n",
    "    return response.json()[\"id\"]\n",
    "\n",
    "def upload_file(batch_id, file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        response = requests.put(\n",
    "            f\"{host}/api/v2/batches/{batch_id}/files/{file_path.split('/')[-1]}\",\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {token}\",\n",
    "                \"Ib-Context\": org\n",
    "            },\n",
    "       verify = False,\n",
    "            data=f.read()\n",
    "        )\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "def run_deployment(batch_id, deployment_id):\n",
    "    response = requests.post(\n",
    "        f\"{host}/api/v2/apps/deployments/{deployment_id}/runs\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Ib-Context\": org\n",
    "        },\n",
    "        json={\n",
    "            \"batch_id\": batch_id,\n",
    "            \"input_dir\": None,\n",
    "            \"manual_upstream_integration\": False,\n",
    "            \"from_timestamp\": None,\n",
    "            \"to_timestamp\": None,\n",
    "            \"version\": None,\n",
    "            \"output_dir\": None,\n",
    "            \"settings\": {\n",
    "                \"keys\": {\n",
    "                    \"custom\": {},\n",
    "                    \"secret\": {}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "       verify = False\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "def run_cases():\n",
    "    cases_dir = \"./cases\"\n",
    "    deployment_id = \"0197785d-8d10-72fa-9499-4019edf1e5ba\"\n",
    "\n",
    "    # Iterate through each case folder\n",
    "    for case_folder in os.listdir(cases_dir):\n",
    "        case_path = os.path.join(cases_dir, case_folder)\n",
    "        \n",
    "        if os.path.isdir(case_path):\n",
    "            print(f\"\\nProcessing case: {case_folder}\")\n",
    "            \n",
    "            # Create new batch for each case\n",
    "            batch_id = create_batch()\n",
    "            \n",
    "            # Upload all files in the case folder\n",
    "            for file_name in os.listdir(case_path):\n",
    "                file_path = os.path.join(case_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    print(f\"Uploading file: {file_name}\")\n",
    "                    file_response = upload_file(batch_id, file_path)\n",
    "            \n",
    "            # Run deployment for this case\n",
    "            run_response = run_deployment(batch_id, deployment_id)\n",
    "            job_id = run_response[\"id\"]\n",
    "            job_ids.append(job_id)\n",
    "            case_names[job_id] = case_folder  \n",
    "            print(f\"Run response for {case_folder}: {run_response}\")\n",
    "\n",
    "def check_status(job_id, threshold=2000):\n",
    "    url = f'{host}/api/v2/apps/runs/{job_id}'\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'IB-Context': org,\n",
    "        'Authorization': f'Bearer {token}'\n",
    "    }\n",
    "    is_running = True\n",
    "    is_timeout = False\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Wait for the job to finish\n",
    "    while is_running:\n",
    "        time.sleep(10)\n",
    "        response = requests.request(\"GET\", url, headers=headers, data=payload, verify = False)\n",
    "        status = json.loads(response.text)['status']\n",
    "        if status not in ['RUNNING', 'PENDING']:\n",
    "            is_running = False\n",
    "        if time.time() - start_time > threshold:\n",
    "            is_running = False\n",
    "            is_timeout = True\n",
    "            break\n",
    "    if is_timeout:\n",
    "        print(f\"Job {job_id} timed out after {threshold} seconds\")\n",
    "    return is_running, is_timeout\n",
    "\n",
    "def fetch_results(job_id):\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'IB-Context': org,\n",
    "        'Authorization': f'Bearer {token}'\n",
    "    }\n",
    "    results = None\n",
    "    file_offset = 0\n",
    "    while True:\n",
    "        results_url = f'{host}/api/v2/apps/runs/{job_id}/results'\n",
    "        params = {\n",
    "            \"include_validation_results\": \"true\",\n",
    "            \"include_source_info\": \"true\",\n",
    "            \"include_confidence_scores\": \"true\",\n",
    "            \"file_offset\": file_offset\n",
    "        }\n",
    "        query_string = \"&\".join(f\"{key}={value}\" for key, value in params.items())\n",
    "        results_url = f\"{results_url}?{query_string}\"\n",
    "\n",
    "        response = requests.request(\"GET\", results_url, headers=headers, data=payload,verify = False)\n",
    "        curr_result = json.loads(response.text)\n",
    "        if results is None:\n",
    "            results = curr_result\n",
    "        else:\n",
    "            results['files'].extend(curr_result.get('files', []))\n",
    "\n",
    "        if not curr_result.get('has_more', False):\n",
    "            break\n",
    "        file_offset += len(curr_result.get('files', []))\n",
    "    return results\n",
    "\n",
    "def process_document_results(results, case_name):\n",
    "    extraction_records = []\n",
    "    validation_records = []\n",
    "    \n",
    "    for file_data in results['files']:\n",
    "        file_name = file_data['original_file_name']\n",
    "        \n",
    "        for document in file_data['documents']:\n",
    "            extraction_record = {\n",
    "                'case_name': case_name,\n",
    "                'filename': file_name,\n",
    "                'classification': document['class_name']\n",
    "            }\n",
    "            validation_record = {\n",
    "                'case_name': case_name, \n",
    "                'filename': file_name,\n",
    "                'classification': document['class_name']\n",
    "            }\n",
    "\n",
    "            print(document)\n",
    "            for field in document['fields']:\n",
    "                field_name = field['field_name']\n",
    "                extraction_record[field_name] = field['value']\n",
    "                print(field)\n",
    "                validations = field.get('validations', {})\n",
    "                if validations:\n",
    "                    validation_record[field_name] = validations.get('valid', False)\n",
    "                else:\n",
    "                    validation_record[field_name] = False\n",
    "\n",
    "            extraction_records.append(extraction_record)\n",
    "            validation_records.append(validation_record)\n",
    "            \n",
    "    return extraction_records, validation_records\n",
    "\n",
    "def get_results():\n",
    "    all_extraction_records = []\n",
    "    all_validation_records = []\n",
    "    \n",
    "    for job_id in job_ids:\n",
    "        job_status, job_timeout = check_status(job_id)\n",
    "        \n",
    "        if not job_status and not job_timeout:\n",
    "            job_results = fetch_results(job_id)\n",
    "            current_case = case_names[job_id]\n",
    "            \n",
    "            print(f\"Processing vcase: {current_case}\")\n",
    "            extraction_records, validation_records = process_document_results(job_results, current_case)\n",
    "            all_extraction_records.extend(extraction_records)\n",
    "            all_validation_records.extend(validation_records)\n",
    "        else:\n",
    "            print(f\"Job {job_id} timed out during processing\")\n",
    "\n",
    "    # Create and save dataframes\n",
    "    extraction_df = pd.DataFrame(all_extraction_records)\n",
    "    validation_df = pd.DataFrame(all_validation_records)\n",
    "    \n",
    "    extraction_df.to_csv('extracted_results.csv', index=False)\n",
    "    validation_df.to_csv('validation_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a3c713-1458-4247-a943-77a1d70d4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing case: case_1\n",
      "munichre GSI-ModelLab 4S6sYTbnpx5WwM6RNQBM5rSWI8JTZR https://munichre-gsi.aihub.instabase.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'munichre-gsi.aihub.instabase.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 597}\n",
      "Uploading file: test.msg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'munichre-gsi.aihub.instabase.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [204]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'munichre-gsi.aihub.instabase.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run response for case_1: {'id': 'dc61f43b-b8de-46e3-b0cc-7fa9b627e46c', 'status': 'RUNNING', 'msg': '', 'start_timestamp': 1750915589866271650, 'finish_timestamp': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'munichre-gsi.aihub.instabase.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:    \n\u001b[32m      2\u001b[39m     run_cases()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 196\u001b[39m, in \u001b[36mget_results\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m all_validation_records = []\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m job_id \u001b[38;5;129;01min\u001b[39;00m job_ids:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     job_status, job_timeout = \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_status \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_timeout:\n\u001b[32m    199\u001b[39m         job_results = fetch_results(job_id)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mcheck_status\u001b[39m\u001b[34m(job_id, threshold)\u001b[39m\n\u001b[32m    112\u001b[39m time.sleep(\u001b[32m10\u001b[39m)\n\u001b[32m    113\u001b[39m response = requests.request(\u001b[33m\"\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m\"\u001b[39m, url, headers=headers, data=payload, verify = \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m status = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstatus\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mRUNNING\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPENDING\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    116\u001b[39m     is_running = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'status'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    run_cases()\n",
    "    get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16277e-b3eb-474d-86b8-27b3bc4a2d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
